# NOTE: On Lambda 24.04 stack, PyTorch 2.7.0 with CUDA 12.8 is pre-installed system-wide.
# For other environments, install torch first with the appropriate wheel:
#   pip install torch==2.7.0 torchvision==0.22.0 --index-url https://download.pytorch.org/whl/cu128
# Then run: pip install -r requirements.txt

torch>=2.7.0
torchvision>=0.22.0
transformers>=4.57.1
datasets>=4.4.0
hf-transfer>=0.1.9
accelerate>=1.11.0
deepspeed>=0.18.2; platform_system == "Linux"
bitsandbytes>=0.48.2; platform_system == "Linux"
tqdm>=4.67.1
peft>=0.17.1
nltk>=3.9.2
scikit-learn>=1.6.0
scipy>=1.16.3
numpy<2.0,>=1.24.0
pandas>=2.3.0
sentence-transformers>=5.1.2
fasttext-wheel>=0.9.2
sentencepiece>=0.2.1
pyarrow>=20.0.0
# flash-attn==2.8.3  # Optional: often fails to build on ARM64/GH200. Pipeline works without it (10-20% slower).
#                    # Install manually if needed: pip install flash-attn==2.8.3
tf-keras>=2.15.0  # Required for transformers compatibility with Keras 3
sacrebleu>=2.4.2
pyyaml>=6.0.1
